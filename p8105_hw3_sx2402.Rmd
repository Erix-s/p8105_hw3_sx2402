---
title: "p8105_hw3_sx2402"
author: "Eric Xu"
date: "2025-10-04"
output: github_document
---
```{r settings,include=FALSE}
library(tidyverse)
library(patchwork)
library(p8105.datasets)
data("instacart")
```

## Problem 1:
```{r skim, eval = FALSE}
instacart_skim = instacart |> 
  mutate(
    user_id = as.character(user_id),
    aisle_id = as.character(aisle_id),
    reordered = as.factor(reordered),
    order_id = as.character(order_id),
    product_id = as.character(product_id),
    department_id = as.character(department_id)
         )

names(instacart_skim)
skimr::skim(instacart_skim)
```
There are 1384617 observations from dataset `instacart` and 131,209 unique users. Each row represents a single product in a customer’s order. There are in total 39123
unique product names. There are total 15 variables, 5 describing identifiers of order, aisle, product, department, and user; and `add_to_cart_order` shows order in which each product was added to cart.


Some other important variables include:

* `redordered`: if this product has been ordered by this user in the past
* `order_number`: the order sequence number for this user (1=first, n=nth)
* `order_dow`: the day of the week on which the order was placed
* `order_hour_of_day`: the hour of the day on which the order was placed
* `days_since_prior_order`: days since the last order, capped at 30, NA if order_number is 1

### Questions:

__How many aisles are there, and which aisles are the most items ordered from?__
```{r Q1, collapse=TRUE}
instacart_skim = instacart |> 
  summarize(
    n_aisle = n_distinct(aisle),
    n_obs = n()
    )
instacart_skim

instacart_skim = instacart |>
  group_by(aisle) |> 
  count(aisle, name = "n_times") |> 
  arrange(desc(n_times))
instacart_skim
```

_There are 134 unique aisles and aisle `fresh vegetables` occurred 150609 times with the the most items ordered from_

__Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.__
```{r Q2,fig.width=8, fig.height=6, dpi=250}
aisle_counts = instacart |> 
  count(aisle, name = "n_times") |> 
  filter(n_times > 10000)

aisle_counts |> 
  mutate(aisle = fct_reorder(aisle, -n_times)) |> 
  ggplot(aes(x = aisle, y = n_times)) +
  geom_bar(stat = "identity")+
   viridis::scale_color_viridis()+
  theme(axis.text.x = element_text(angle=90, size=9, hjust=1, vjust=0.5))+
  labs(
    title = "Number of items ordered by aisle",
    x = "Aisle",
    y = "Number of items ordered"
  )
```
Fresh vegetables and fresh fruits has overwhelming purchase number across all aisles with around 150000 and packaged vegetables and yogurt follows with around 50000 to 100000. This shows a high demand on healthy food and fresh vegetable and fruits purchased in online grocery.

__Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.__

```{r Q3}
top_items = instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  count(aisle,product_name, name = "times") |>
  group_by(aisle) |> 
  arrange(desc(times)) |> 
  slice_max(times, n =3)
knitr::kable(top_items)
```
The most popular items for baking ingredients has around 300 too 500 times of purchase which are all common used ingredient;the three product has low variation in purchase. The dog food care has less online purchases with 26 to 30 that are has one snack and other two chicken and rice favored;;the three product has low variation in purchase. For vegetables, around 5000 to 10000 purchases for the first three product that are all organic with 2 berries of similar purchases and baby spinach with highest times ordered.

__Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).__
```{r Q4, message=FALSE}
#extract and DOW transform
mean_hours = instacart |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  group_by(product_name,order_dow) |> 
  summarize(
    mean_hour = mean(order_hour_of_day)
    ) |> 
  mutate(order_dow = case_when(
    order_dow == 0 ~ "Sunday",
    order_dow == 1 ~ "Monday",
    order_dow == 2 ~ "Tuesday",
    order_dow == 3 ~ "Wednesday",
    order_dow == 4 ~ "Thursday",
    order_dow == 5 ~ "Friday",
    order_dow == 6 ~ "Saturday"
  )) |> 
  pivot_wider(names_from = order_dow, values_from = mean_hour) |> 
  rename("Product Name" = "product_name")


knitr::kable(mean_hours, digits = 2)
```
The purchase time of Ice cream is on average late afternoon around 3pm from Monday to Thursday as workdays. On Friday to Sunday with spare time, the purchase time is more close to noon and the product seems to be preferred as snack after lunch. The apple has a relatively earlier purchase throughout the week and no significant difference in average purchase time across all week that all are purchased around noon which is center of time distribution showing not significant preference of purchase time. While it can also relate to observations that healthier snacks and staples tend to be purchased earlier in the day and Ice cream and frozen pizza are the most frequently ordered products late at night.

## Problem 2
__Import Dataset__
```{r P2 data import, message = FALSE}
zip_code = read_csv("./Data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  select(-file_date)

zori = read.csv("./Data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  filter(region_type == "zip")|> 
  rename(
    zip_code = region_name,
    zori_county = county_name
         )|> 
  select(-region_type)

zori_long = zori |> 
  pivot_longer(x2015_01_31:x2024_08_31,
               names_to = "date",
               values_to = "zori",
               names_prefix = "x",
               )
zori_zip = left_join(zori_long,zip_code,by="zip_code",relationship = "many-to-many")
```
__How many ZIP codes are observed 116 times? How many are observed fewer than 10 times? Why are some ZIP codes are observed rarely and others observed in each month?__
```{r P2.1, collapse=TRUE}
zip_counts = zori_zip |> 
  filter(is.na(zori) == FALSE) |> 
  group_by(zip_code) |> 
  summarize(
    n_obs = n()
    )|> 
  filter (n_obs == 116 | n_obs<10)

#count
zip_counts |> 
  summarize(
    count1 = sum(n_obs == 116),
    count2 = sum(n_obs < 10)
  ) 

#filter obs
zori_counts = left_join(zip_counts,zori_zip, by = "zip_code") |> 
  filter(n_obs < 10 | n_obs == 116) |> 
  group_by(zip_code) |> 
  arrange(n_obs) |> 
  distinct(zip_code, zori_county, n_obs)
zori_counts
```
There are 47 ZIP codes observed 116 times and 26 fewer than 10 times. The counties has little observation are relatively distinct and is likely to be not rental or not residential so that not enough observation and data can be collected through rental pricing. While the zip codes observed every month are in majority of New York County and Queens where rental is a general option and data is collected easity with large amount of rental deals.


__Create a reader-friendly table showing the average rental price in each borough and year (not month). Comment on trends in this table.__
```{r P2.2, message = FALSE}
#date to year
zori_zip_table = zori_zip |> 
  filter(!is.na(zori)) |> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    year = year(date)
  )

#average price
zori_zip_table = zori_zip_table |>  
  group_by(county, year) |> 
  summarize(
    avg_rent = mean(zori, na.rm = TRUE)
  ) |> 
  pivot_wider(
    names_from = year,
    values_from = avg_rent
  )


knitr::kable(zori_zip_table, digits = 1)

#check NA in Richmond
zori_zip |> 
  filter(
    county == "Richmond",
    !is.na(zori)
  ) |> 
  summarize(
    mindate = min(date),
    maxdate = max(date)
  )
```
The average rental price increases by year from 2015 to 2024 across all counties and with a slower increase in 2021 where pandemic reduces the demand of rental. Also, Richmond has no information on rental untile 2020. The New York county has on average highest rental price and Bronx has the lowest possibly due to resource, access, and safety concerns.

__Plotting Rental Prices within ZIP__
```{r P2.3, fig.height=8, fig.width=10,dpi=250}
zori_zip_plot = zori_zip|> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    year = year(date)
         ) |> 
  select(zori, year, county,zip_code,date) |> 
  drop_na(zori)
zori_zip_plot_p =
  ggplot(zori_zip_plot,aes(x = date, y = zori, group = zip_code, color = county, na.rm = TRUE)) +
  geom_point(alpha = 0.4, size = 0.4)  +
  geom_line(alpha = 0.4, linewidth = 0.4)+
  facet_wrap(~ county, strip.position = "bottom", ncol = 1, nrow=5)+
  labs(
    title = "NYC Rental Prices by ZIP Code",
    x = "Year",
    y = "Average Rental Price")+
  scale_x_date(date_breaks = "3 years", date_labels = "%Y")
zori_zip_plot_p
```

NYC rental prices have generally increased across all boroughs from 2015 to 2024, with a sharp drop in 2021 that aligns with the COVID-19 which has impacted demand. After the pandemic, prices restored to original place and continued to rise. Manhattan (New York County) consistently has the highest rental levels and most available records zip codes, while Brooklyn (Kings County) follows with moderately high prices. Queens and the Bronx show lower but steadily increasing rents, and Richmond (Staten Island) appears later in the data, after 2021, with comparatively lower rental prices.


__Average Rental Price within each ZIP Plot__
```{r P2.4, dpi=250, fig.width= 15, fig.height=8}
zori_2023 = zori_zip |>
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    year = year(date),
    month = month(date)
    )|> 
  filter(year == 2023) |> 
  group_by(zip_code, county, month) |> 
  summarize(
    avg_rent = mean(zori, na.rm = TRUE),
    .groups = "drop"
  )

zori_2023_p = ggplot(zori_2023, aes(x = county, y = avg_rent)) +
  geom_violin(alpha = 0.6, aes(fill = county),color = "blue", na.rm = TRUE)+
  labs(
    title = "Monthly Rental Price by Zip",
    x = "County",
    y = "Average Monthly Rent"
  ) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
zori_2023_p

combined_plot =
  (zori_2023_p | zori_zip_plot_p)
combined_plot
ggsave(filename = "./result/combined.png",plot = combined_plot, width = 15, height = 8, dpi = 300)
```

Manhattan (New York County) shows the highest average rental prices with wide distribution with highest variation to 8000. Indicating both very expensive priced max rental price and high minimum rental price among all ZIP codes within the county. Brooklyn (Kings County) and Queens follows, also with a narrower distribution  generally lower than Manhattan but higher than others. Richmond and the Bronx display lower median rents and Richmond (Staten Island) has the narrowest distribution, reflecting relatively limited variation due to little sample.

## Problem 3
__Data Import__
```{r P3.1, message = FALSE}
covar = read_csv("./Data/nhanes_covar.csv",skip = 4) |> 
  janitor::clean_names()
accel = read_csv("./Data/nhanes_accel.csv")|> 
  janitor::clean_names()

covar_accel = left_join(covar,accel, by = "seqn") |> 
  filter(
    age>=21,
    !is.na(sex), 
    !is.na(age), 
    !is.na(education)
    ) |> 
  mutate(
    sex = factor(sex,
                 levels = c(1, 2),
                 labels = c("Male", "Female"),
                 ordered = FALSE),
    
    education = factor(education,
                       levels = c(1, 2, 3),
                       labels = c("Less than high school",
                                  "High school equivalent",
                                  "More than high school"),
                       ordered = TRUE)
  )
```

__Table and Plots__
```{r P3.2}
knitr::kable(count(covar_accel, education, sex))
```

Among the selected sample, the distribution of individual across each education level is similar across sex, though there is more male in High school equivalent level compared to female. There are overall more individuals in More than high school education level compared to other 2 with less experience in school.

```{r P3.3}
covar_accel |> 
  ggplot(aes(x = age,fill=sex))+
  geom_density(alpha = .3, adjust = .5)+
  geom_rug()+
  facet_grid(~education)+
  viridis::scale_fill_viridis(discrete = TRUE)
```

The plot shows the age distribution of male and female across different education levels. There is a wide spread range from 21 to 80. The male and female density map overlaps generally in all three maps showing a relatively stable distribution except for variation in 20-40 years old individuals in High school equivalent level. Overall, the age distribution is different in three groups where More than high school individuals are more dense in younger ages and Less than high school groups are more dense in elderly. For High school equivalent, there are more elderly female while male has a generally averaged distribution across all ages.

```{r P3.4, message = FALSE}
accel_long <- covar_accel |> 
  pivot_longer(
    cols = starts_with("min"),
    names_prefix = "min",
    names_to = "minute", 
    values_to = "activity"
  ) |> 
  mutate(
    minute = as.numeric(minute),
    hour = minute / 60
  )

total_activity <- accel_long |> 
  group_by(seqn, age, sex, education) |> 
  summarize(
    total_activity = sum(activity, na.rm = TRUE),
    .groups = "drop"
  )

ggplot(total_activity, aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6, size = 1) +
  geom_smooth(se = FALSE) +
  facet_wrap(~education) +
  labs(
    title = "Total Daily Accelerometer Activity vs Age by Education Level",
    x = "Age",
    y = "Total Daily Activity",
    color = "Sex"
  ) +
  theme_minimal() +
  viridis::scale_color_viridis(discrete = TRUE)
```

Daily physical activity generally declines with age across all education levels. Female show higher total activity than men across a majority of groups, except for individuals over 60 in the Less than high school category, where men show slightly higher activity. The decline in activity is higher in scale among participants with lower educational attainment, likely reflecting differences in SES, occupational demands, and retirement patterns. In contrast, participants with higher education maintain relatively higher activity levels, possibly due to greater health awareness, access to resources, and structured leisure-time activities. The variation of activity is high and the trend is created by smooth function as an approximate estimate which may not be fitting the real situation.

```{r P3.5, message = FALSE}
ggplot(accel_long, aes(x = hour, y = activity, color = sex)) +
  stat_summary(fun = "mean", geom = "point", size = 0.1, alpha = 0.2) +
  facet_grid(~education)+
  labs(title = "24-Hour Accelerometer Activity Profiles by Education Level",
       x = "Time of Day",
       y = "Mean Activity",
       color = "Sex") +
  scale_x_continuous(limits = c(0, 24),breaks = seq(0, 24, 4))+
  geom_smooth(se = FALSE, alpha = 0.5) +
  theme_minimal()
```

With the plot of 24-hour mean activity of individuals over 21 years old, there is clear diurnal rhythm activity and a peak of activity interval appears around 9 until 20. In general, female performs higher mean activity by accelerator measuring compared to male in mean value. This difference is more significant for groups with higher education level that more obvious in High School Equivalent level and most obvious in More than high school level. Also, the average activity seems to fall shortly after 12 which may due to lunch and rest. Also, smoother peaks can be observed in higher education levels which can be due to SES and occupations within stable environment. The variation can also arise from the age distribution in sample since the variation would be large for different stages in life.