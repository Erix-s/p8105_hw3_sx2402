---
title: "p8105_hw3_sx2402"
author: "Eric Xu"
date: "2025-10-04"
output: github_document
---
```{r settings,include=FALSE}
library(p8105.datasets)
library(tidyverse)
data("instacart")
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
```

## Problem 1:
```{r skim, eval = FALSE}
instacart_skim = instacart |> 
  mutate(
    user_id = as.character(user_id),
    aisle_id = as.character(aisle_id),
    reordered = as.factor(reordered),
    order_id = as.character(order_id),
    product_id = as.character(product_id),
    department_id = as.character(department_id)
         )

names(instacart_skim)
skimr::skim(instacart_skim)
```
There are 1384617 observations from dataset `instacart` and 131,209 unique users. Each row represents a single product in a customer’s order. There are in total 39123
unique product names. There are total 15 variables, 5 describing identifiers of order, aisle, product, department, and user; and `add_to_cart_order` shows order in which each product was added to cart.


Some other important variables include:

* `redordered`: if this product has been ordered by this user in the past
* `order_number`: the order sequence number for this user (1=first, n=nth)
* `order_dow`: the day of the week on which the order was placed
* `order_hour_of_day`: the hour of the day on which the order was placed
* `days_since_prior_order`: days since the last order, capped at 30, NA if order_number is 1

### Questions:

__How many aisles are there, and which aisles are the most items ordered from?__
```{r Q1, collapse=TRUE}
instacart_skim = instacart |> 
  summarize(
    n_aisle = n_distinct(aisle),
    n_obs = n()
    )
instacart_skim

instacart_skim = instacart |>
  group_by(aisle) |> 
  count(aisle, name = "n_times") |> 
  arrange(desc(n_times))
instacart_skim
```

_There are 134 unique aisles and aisle `fresh vegetables` occurred 150609 times with the the most items ordered from_

__Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.__
```{r Q2,fig.width=8, fig.height=6, dpi=250}
aisle_counts = instacart |> 
  count(aisle, name = "n_times") |> 
  filter(n_times > 10000)

aisle_counts |> 
  mutate(aisle = fct_reorder(aisle, -n_times)) |> 
  ggplot(aes(x = aisle, y = n_times)) +
  geom_bar(stat = "identity")+
   viridis::scale_color_viridis()+
  theme(axis.text.x = element_text(angle=90, size=9, hjust=1, vjust=0.5))+
  labs(
    title = "Number of items ordered by aisle",
    x = "Aisle",
    y = "Number of items ordered"
  )
```

__Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.__

```{r Q3}
top_items = instacart |> 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) |> 
  count(aisle,product_name, name = "times") |>
  group_by(aisle) |> 
  arrange(desc(times)) |> 
  slice_max(times, n =3)
knitr::kable(top_items)
```


__Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).__
```{r Q4, message=FALSE}
#extract and DOW transform
mean_hours = instacart |> 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |> 
  group_by(product_name,order_dow) |> 
  summarize(
    mean_hour = mean(order_hour_of_day)
    ) |> 
  mutate(order_dow = case_when(
    order_dow == 0 ~ "Sunday",
    order_dow == 1 ~ "Monday",
    order_dow == 2 ~ "Tuesday",
    order_dow == 3 ~ "Wednesday",
    order_dow == 4 ~ "Thursday",
    order_dow == 5 ~ "Friday",
    order_dow == 6 ~ "Saturday"
  )) |> 
  pivot_wider(names_from = order_dow, values_from = mean_hour) |> 
  rename("Product Name" = "product_name")


knitr::kable(mean_hours, digits = 2)
```

## Problem 2
__Import Dataset__
```{r P2 data import, message = FALSE}
zip_code = read_csv("./Data/Zip Codes.csv") |> 
  janitor::clean_names() |> 
  select(-file_date)

zori = read.csv("./Data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  filter(region_type == "zip")|> 
  rename(
    zip_code = region_name,
    zori_county = county_name
         )|> 
  select(-region_type)

zori_long = zori |> 
  pivot_longer(x2015_01_31:x2024_08_31,
               names_to = "date",
               values_to = "zori",
               names_prefix = "x",
               )
zori_zip = left_join(zori_long,zip_code,by="zip_code",relationship = "many-to-many")
```
__How many ZIP codes are observed 116 times? How many are observed fewer than 10 times? Why are some ZIP codes are observed rarely and others observed in each month?__
```{r P2.1, collapse=TRUE}
zip_counts = zori_zip |> 
  filter(is.na(zori) == FALSE) |> 
  group_by(zip_code) |> 
  summarize(
    n_obs = n()
    )|> 
  filter (n_obs == 116 | n_obs<10)

#count
zip_counts |> 
  summarize(
    count1 = sum(n_obs == 116),
    count2 = sum(n_obs < 10)
  ) 

#filter obs
zori_counts = left_join(zip_counts,zori_zip, by = "zip_code") |> 
  filter(n_obs < 10 | n_obs == 116) |> 
  group_by(zip_code) |> 
  arrange(n_obs) |> 
  distinct(zip_code, zori_county, n_obs)
zori_counts
```
There are 47 ZIP codes observed 116 times and 26 fewer than 10 times. The counties has little observation are relatively distinct and is likely to be not rental or not residential so that not enough observation and data can be collected through rental pricing. While the zip codes observed every month are in majority of New York County and Queens where rental is a general option and data is collected easity with large amount of rental deals.


__Create a reader-friendly table showing the average rental price in each borough and year (not month). Comment on trends in this table.__
```{r P2.2, message = FALSE}
#date to year
zori_zip_table = zori_zip |> 
  filter(!is.na(zori)) |> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    year = year(date)
  )

#average price
zori_zip_table = zori_zip_table |>  
  group_by(county, year) |> 
  summarize(
    avg_rent = mean(zori, na.rm = TRUE)
  ) |> 
  pivot_wider(
    names_from = year,
    values_from = avg_rent
  )


knitr::kable(zori_zip_table, caption = "Average Rental Price by Borough and Year (NYC)")

#check NA in Richmond
zori_zip |> 
  filter(
    county == "Richmond",
    !is.na(zori)
  ) |> 
  summarize(
    mindate = min(date),
    maxdate = max(date)
  )
```

__Plotting Rental Prices within ZIP__
```{r P2.3, fig.height=8, fig.width=10,dpi=250}
zori_zip_plot = zori_zip|> 
  mutate(
    date = as.Date(date, format = "%Y_%m_%d"),
    year = year(date)
         ) |> 
  select(zori, year, county,zip_code,date) |> 
  drop_na(zori)
zori_zip_plot |> 
  ggplot(aes(x = date, y = zori, group = zip_code, color = county, na.rm = TRUE)) +
  geom_point(alpha = 0.3, size = 0.5)  +
  geom_line(alpha = 0.3, linewidth = 0.5)+
  facet_wrap(~ county, scales ="free_y", strip.position = "bottom", ncol = 1, nrow=5)+
  theme_minimal() +
  labs(
    title = "NYC Rental Prices by ZIP Code (2015–2024)",
    subtitle = "Line for same ZIP code",
    x = "Year",
    y = "Average Rental Price")+
  scale_x_date(date_breaks = "2 years", date_labels = "%Y")
```

NYC rental prices have generally increased across all boroughs from 2015 to 2024, with a sharp drop in 2021 that aligns with the COVID-19 which has impacted demand. After the pandemic, prices restored to original place and continued to rise. Manhattan (New York County) consistently has the highest rental levels and most available records zip codes, while Brooklyn (Kings County) follows with moderately high prices. Queens and the Bronx show lower but steadily increasing rents, and Richmond (Staten Island) appears later in the data, after 2021, with comparatively lower rental prices.


__Average Rental Price within each ZIP Plot__
